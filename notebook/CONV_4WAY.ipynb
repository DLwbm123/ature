{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import PIL.Image as IMG\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "# Other imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# NOTE: Aashis, you should use the training images to develop your algorithm.\n",
    "# The test images should be reserved for validating its performance afterwards\n",
    "# os.chdir('/home/ak/Spring2018/ature')\n",
    "os.chdir('/home/ak/Spring2018/ature')\n",
    "from utils import img_utils as imgutil\n",
    "\n",
    "sep = os.sep\n",
    "\n",
    "# Define folders (create them if needed)\n",
    "Dirs = {}\n",
    "Dirs['train_data']      = 'data'+sep+'DRIVE'+sep+'training'+sep +'patches'\n",
    "Dirs['test_data']      = 'data'+sep+'DRIVE'+sep+'test'+sep +'patches'\n",
    "\n",
    "# Set up execution flags\n",
    "Flags = {}\n",
    "Flags['useGPU'] = False\n",
    "\n",
    "classes = ('white', 'green', 'black', 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DriveDataset(Dataset):\n",
    "    \n",
    "    # data_path should contain pickled numpy array of dimension N * (D+1)\n",
    "    # Where extra one dimension stores the correct lable among (0, 1, 2, 3)\n",
    "    \n",
    "    def __init__(self, data_path=None, height=None, width=None, transform=None):\n",
    "        \n",
    "        \n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.data = None\n",
    "        for data_file in os.listdir(data_path):\n",
    "            \n",
    "            data_file = os.path.join(data_path, data_file)\n",
    "            print('Data file: ' + data_file)\n",
    "            if self.data is None:\n",
    "                self.data = np.load(data_file)\n",
    "            else:\n",
    "                self.data = np.concatenate((self.data, np.load(data_file)), axis=0)\n",
    "            \n",
    "    \n",
    "        self.labels = torch.from_numpy(self.data[:, self.height * self.width]) \n",
    "        self.data = self.data[:,0:self.height * self.width]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        img_arr = self.data[index].reshape(self.height, self.width)\n",
    "        img = IMG.fromarray(imgutil.whiten_image2d(img_arr))\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img_tensor = self.transform(img)\n",
    "            \n",
    "        return (img_tensor, self.labels[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "trainset = DriveDataset(data_path=Dirs['train_data'], height=31, width=31, transform=transform)\n",
    "clss, class_counts = np.unique(trainset.labels, return_counts=True)\n",
    "class_weights = 1.0/class_counts\n",
    "data_weights = np.array([class_weights[t] for t in trainset.labels]) \n",
    "second_min_class_count =  np.partition(class_counts, 1)[1]\n",
    "\n",
    "sampler = WeightedRandomSampler(data_weights, int(second_min_class_count))\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=False, num_workers=1, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG.fromarray(trainset.data[3000].reshape(31,31))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, width, channels):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.channels = channels\n",
    "        self.width = width\n",
    "        \n",
    "        \n",
    "        self.kern_size = 5\n",
    "        self.kern_stride = 2      \n",
    "        self.kern_padding = 2\n",
    "        \n",
    "        self.mxp_kern_size = 2\n",
    "        self.mxp_stride = 2 \n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=self.mxp_kern_size, stride=self.mxp_stride)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(self.channels, 20, self.kern_size, \n",
    "                               stride=self.kern_stride, padding=self.kern_padding)\n",
    "        self._update_output_size()\n",
    "        \n",
    "        \n",
    "        self.kern_size = 5\n",
    "        self.kern_stride = 1      \n",
    "        self.kern_padding = 1\n",
    "        \n",
    "        self.mxp_kern_size = 1\n",
    "        self.mxp_stride = 1 \n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=self.mxp_kern_size, stride=self.mxp_stride)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(20, 50, self.kern_size, \n",
    "                               stride=self.kern_stride, padding=self.kern_padding)\n",
    "        self._update_output_size()\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.linearWidth = 50*int(self.width)*int(self.width)\n",
    "        self.fc1 = nn.Linear(self.linearWidth, 30)\n",
    "        self.fc2 = nn.Linear(30, 10)\n",
    "        self.fc3 = nn.Linear(10, 4)\n",
    "        self.sm = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, self.linearWidth)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def _update_output_size(self):       \n",
    "        self.width = ((self.width - self.kern_size + 2 * self.kern_padding) / self.kern_stride) + 1\n",
    "        temp = self.width\n",
    "        self.width = ((self.width - self.mxp_kern_size)/self.mxp_stride) + 1\n",
    "        print('output width { conv: ' + str(temp) + ', maxpool: ' + str(self.width) + ' }')\n",
    "\n",
    "width = 31\n",
    "channels = 1\n",
    "net = Net(width, channels)\n",
    "\n",
    "# Send network to the GPU, if requested\n",
    "if Flags['useGPU']:\n",
    "    net.cuda()\n",
    "\n",
    "# Define loss criterion\n",
    "# criterion = nn.L1Loss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(10): \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        if Flags['useGPU']:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())                \n",
    "        else:                \n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics every 500 mini-batches\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 1000 == 999:\n",
    "            print('[epoch: %d, batches: %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = DriveDataset(data_path=Dirs['test_data'], height=31, width=31, transform=transform)\n",
    "clss_test, class_counts_test = np.unique(testset.labels, return_counts=True)\n",
    "class_weights_test = 1.0/class_counts_test\n",
    "\n",
    "data_weights_test = np.array([class_weights_test[t] for t in testset.labels])\n",
    "data_weights_test = np.ones_like(testset.labels)\n",
    "\n",
    "second_min_class_count_test =  np.partition(class_counts_test, 1)[1]\n",
    "\n",
    "sampler_test = WeightedRandomSampler(data_weights_test, int(second_min_class_count_test))\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=2, shuffle=False, num_workers=1, sampler=sampler_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    \n",
    "    images, labels = data  \n",
    "    if Flags['useGPU']:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "    if i % 500 == 499:\n",
    "        print('Accuracy of %d batches of test images: %d %%' % (i+1, 100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check per-class performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(4))\n",
    "class_total = list(0. for i in range(4))\n",
    "i = 0\n",
    "for data in testloader:\n",
    "    \n",
    "    images, labels = data\n",
    "    \n",
    "    if Flags['useGPU']:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    for i in range(2):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "    i = i+1\n",
    "    if i > 10000:\n",
    "        break\n",
    "\n",
    "for i in range(4):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ature_env",
   "language": "python",
   "name": "ature_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
