{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook loads and train data from the directories without having them to load on memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/ak/Spring2018/ature')\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import neuralnet.utils.data_utils as dutils\n",
    "from neuralnet.utils.keras_dataset import KerasPatchesGenerator\n",
    "from commons.IMAGE import Image\n",
    "from PIL import Image as IMG\n",
    "import utils.img_utils as imgutils\n",
    "from keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directories setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define folders. Create if needed.\n",
    "sep = os.sep\n",
    "Dirs = {}\n",
    "Dirs['checkpoint']   = 'assests' +sep+ 'nnet_models'\n",
    "Dirs['data']      = 'data'+sep+'DRIVE'+sep+'training'\n",
    "Dirs['images']    = Dirs['data'] +sep+ 'images1'\n",
    "Dirs['mask']      = Dirs['data'] +sep+ 'mask'\n",
    "Dirs['truth']     = Dirs['data'] +sep+ '1st_manual'\n",
    "Dirs['segmented'] = Dirs['data'] +sep+ 'drive_segmented'\n",
    "\n",
    "TestDirs = {}\n",
    "TestDirs['data']      = 'data'+sep+'DRIVE'+sep+'test'\n",
    "TestDirs['images']    = TestDirs['data'] +sep+ 'test_images'\n",
    "TestDirs['mask']      = TestDirs['data'] +sep+ 'mask'\n",
    "TestDirs['truth']     = TestDirs['data'] +sep+ '1st_manual'\n",
    "TestDirs['segmented'] = TestDirs['data'] +sep+ 'drive_segmented'\n",
    "\n",
    "ValidationDirs = {}\n",
    "ValidationDirs['data']      = 'data'+sep+'DRIVE'+sep+'test'\n",
    "ValidationDirs['images']    = ValidationDirs['data'] +sep+ 'validation_images'\n",
    "ValidationDirs['mask']      = ValidationDirs['data'] +sep+ 'mask'\n",
    "ValidationDirs['truth']     = ValidationDirs['data'] +sep+ '1st_manual'\n",
    "ValidationDirs['segmented'] = ValidationDirs['data'] +sep+ 'drive_segmented'\n",
    "\n",
    "for k, folder in Dirs.items():\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "def get_mask_file(file_name): \n",
    "    return file_name.split('_')[0] + '_training_mask.gif'\n",
    "\n",
    "def get_ground_truth_file(file_name): \n",
    "    return file_name.split('_')[0] + '_manual1.gif'\n",
    "\n",
    "def get_segmented_file(file_name):\n",
    "    return file_name + '_SEG.PNG'\n",
    "\n",
    "def get_mask_file_test(file_name): \n",
    "    return file_name.split('_')[0] + '_test_mask.gif'\n",
    "\n",
    "classes = {\n",
    "    'background': 0,\n",
    "    'vessel': 1,\n",
    "}\n",
    "batch_size = 52\n",
    "num_classes = len(classes)\n",
    "epochs = 2\n",
    "patch_size = 31\n",
    "checkpoint = 'keras_model_checkpoint.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traingen = ImageDataGenerator(\n",
    "    rotation_range=70,\n",
    "    horizontal_flip=True,\n",
    "    samplewise_center=True,\n",
    "    samplewise_std_normalization=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "testgen = ImageDataGenerator(\n",
    "    samplewise_center=True,\n",
    "    samplewise_std_normalization=True,\n",
    ")\n",
    "\n",
    "train_generator = KerasPatchesGenerator(Dirs=Dirs, patch_size=patch_size, \n",
    "                                   num_classes=num_classes,\n",
    "                                   fget_mask=get_mask_file, \n",
    "                                   fget_truth=get_ground_truth_file,\n",
    "                                   batch_size=batch_size, img_generator=traingen, shuffle=True)\n",
    "\n",
    "validation_generator = KerasPatchesGenerator(Dirs=ValidationDirs, patch_size=patch_size, \n",
    "                                   num_classes=num_classes,\n",
    "                                   fget_mask=get_mask_file_test, \n",
    "                                   fget_truth=get_ground_truth_file,\n",
    "                                   batch_size=batch_size, img_generator=testgen)\n",
    "\n",
    "test_generator = KerasPatchesGenerator(Dirs=TestDirs, patch_size=patch_size, \n",
    "                                   num_classes=num_classes,\n",
    "                                   fget_mask=get_mask_file_test, \n",
    "                                   fget_truth=get_ground_truth_file,\n",
    "                                   batch_size=batch_size, img_generator=testgen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() \n",
    "\n",
    "model.add(Conv2D(52, (3, 3), padding='same', input_shape=(patch_size, patch_size, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate Adam optimizer\n",
    "opt = keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using Adam\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=Dirs['checkpoint'] +  sep+ checkpoint, verbose=1, save_best_only=True)\n",
    "tensorboard = TensorBoard(log_dir=\"logs/keras/{}\".format(time()), write_grads=True, write_images=True,\n",
    "                          histogram_freq=1, write_graph=True, batch_size=1)\n",
    "callbacks = [tensorboard]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model from directory generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = dutils.get_class_weights(np.array(train_generator.IDs)[:,3])\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=1000,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800, verbose=1,\n",
    "        callbacks=callbacks, workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### If we shuffle, we won't be able to generate a segmented image.\n",
    "prediction = model.predict_generator(test_generator, workers=3)\n",
    "pred = np.argmax(prediction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_obj = Image()\n",
    "img_obj.load_file(data_dir=Dirs['images'], file_name='21_training.tif')\n",
    "img_obj.working_arr = img_obj.image_arr[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = np.zeros_like(img_obj.working_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, IDij in enumerate(test_generator.IDs, 0):\n",
    "    ID, i, j = IDij\n",
    "    try:\n",
    "        if pred[ix]==classes['white'] or pred[ix]==classes['red']:\n",
    "            seg[int(i),int(j)] = 255\n",
    "    except:\n",
    "        print('Ouch!', end='\\r')\n",
    "IMG.fromarray(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SANITY CHECK\n",
    "for ID, i, j, y in train_generator.IDs:\n",
    "    if ID==0:\n",
    "        seg[i,j] = 255 if y == 0 or y == 3 else seg[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.shuffle = True\n",
    "test_generator.batch_size =1\n",
    "for x, y in test_generator:\n",
    "    m = model.predict_classes(x)\n",
    "    if m[0]==1:\n",
    "        print(m)\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jj = np.squeeze(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jj = imgutils.rescale2d_unsigned(jj) * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG.fromarray(np.array(jj, dtype=np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%s'%('haha'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.full((20,20), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0,3,4,5,6]\n",
    "z = [10,20,31,55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[y] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ature_env",
   "language": "python",
   "name": "ature_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
