{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ak/anaconda/envs/ature_env/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#!/home/akhanal1/Spring2018/pl-env/bin/python3.5\n",
    "# Torch imports\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/ak/Spring2018/ature')\n",
    "os.chdir('/home/ak/Spring2018/ature')\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import PIL.Image as IMG\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from commons.segmentation import AtureTest\n",
    "from commons.IMAGE import SegmentedImage\n",
    "\n",
    "\n",
    "from utils import img_utils as imgutil\n",
    "from commons.IMAGE import Image\n",
    "from neuralnet.simplenet.simplenet_trainer import SimpleNNTrainer\n",
    "from neuralnet.simplenet.simplenet_dataloader import PatchesGenerator\n",
    "import neuralnet.utils.measurements as mnt\n",
    "import neuralnet.utils.data_utils as nndutils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define folders. Create if needed.\n",
    "sep = os.sep\n",
    "Dirs = {}\n",
    "Dirs['checkpoint']   = 'assests' +sep+ 'nnet_models'\n",
    "Dirs['data']      = 'data'+sep+'DRIVE'+sep+'training'\n",
    "Dirs['images']    = Dirs['data'] +sep+ 'images'\n",
    "Dirs['mask']      = Dirs['data'] +sep+ 'mask'\n",
    "Dirs['truth']     = Dirs['data'] +sep+ '1st_manual'\n",
    "\n",
    "TestDirs = {}\n",
    "TestDirs['data']      = 'data'+sep+'DRIVE'+sep+'test'\n",
    "TestDirs['images']    = TestDirs['data'] +sep+ 'test_images'\n",
    "TestDirs['mask']      = TestDirs['data'] +sep+ 'mask'\n",
    "TestDirs['truth']     = TestDirs['data'] +sep+ '1st_manual'\n",
    "\n",
    "ValidationDirs = {}\n",
    "ValidationDirs['data']      = 'data'+sep+'DRIVE'+sep+'test'\n",
    "ValidationDirs['images']    = ValidationDirs['data'] +sep+ 'validation_images'\n",
    "ValidationDirs['mask']      = ValidationDirs['data'] +sep+ 'mask'\n",
    "ValidationDirs['truth']     = ValidationDirs['data'] +sep+ '1st_manual'\n",
    "\n",
    "for k, folder in Dirs.items():\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "for k, folder in TestDirs.items():\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "for k, folder in ValidationDirs.items():\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "def get_mask_file(file_name): \n",
    "    return file_name.split('_')[0] + '_training_mask.gif'\n",
    "\n",
    "def get_ground_truth_file(file_name): \n",
    "    return file_name.split('_')[0] + '_manual1.gif'\n",
    "\n",
    "def get_mask_file_test(file_name): \n",
    "    return file_name.split('_')[0] + '_test_mask.gif'\n",
    "\n",
    "classes = { 'background': 0, 'vessel': 1,}\n",
    "batch_size = 52\n",
    "num_classes = len(classes)\n",
    "epochs = 2\n",
    "patch_size = 51\n",
    "use_gpu = False\n",
    "\n",
    "#### Images to train/validate per epoch ####\n",
    "train_size = 50000\n",
    "validation_size = 5000\n",
    "checkpoint_file = 'PytorchCheckpoint51.nn.tar'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output width[ 51 -conv-> 22.0 -maxpool-> 22.0 ]\n",
      "Output width[ 22.0 -conv-> 24.0 -maxpool-> 12.0 ]\n",
      "Output width[ 12.0 -conv-> 10.0 -maxpool-> 5.0 ]\n",
      "Output width[ 5.0 -conv-> 3.0 -maxpool-> 3.0 ]\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, width, channels):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.channels = channels\n",
    "        self.width = width\n",
    "    \n",
    "        self.kern_size = 11\n",
    "        self.kern_stride = 2   \n",
    "        self.kern_padding = 1\n",
    "        self.mxp_kern_size = 1\n",
    "        self.mxp_stride = 1 \n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=self.mxp_kern_size, stride=self.mxp_stride)\n",
    "        self.conv1 = nn.Conv2d(self.channels, 24, self.kern_size, \n",
    "                               stride=self.kern_stride, padding=self.kern_padding)\n",
    "        self._update_output_size()\n",
    "        \n",
    "        self.kern_size = 5\n",
    "        self.kern_stride = 1     \n",
    "        self.kern_padding = 3\n",
    "        self.mxp_kern_size = 2\n",
    "        self.mxp_stride = 2 \n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=self.mxp_kern_size, stride=self.mxp_stride)\n",
    "        self.conv2 = nn.Conv2d(24, 52, self.kern_size, \n",
    "                               stride=self.kern_stride, padding=self.kern_padding)\n",
    "        self._update_output_size()\n",
    "        \n",
    "        self.kern_size = 5\n",
    "        self.kern_stride = 1      \n",
    "        self.kern_padding = 1\n",
    "        self.mxp_kern_size = 2\n",
    "        self.mxp_stride = 2 \n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=self.mxp_kern_size, stride=self.mxp_stride)\n",
    "        self.conv3 = nn.Conv2d(52, 96, self.kern_size, \n",
    "                               stride=self.kern_stride, padding=self.kern_padding)\n",
    "        self._update_output_size()\n",
    "        \n",
    "        self.kern_size = 3\n",
    "        self.kern_stride = 2  \n",
    "        self.kern_padding = 1\n",
    "        self.mxp_kern_size = 1\n",
    "        self.mxp_stride = 1 \n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=self.mxp_kern_size, stride=self.mxp_stride)\n",
    "        self.conv4 = nn.Conv2d(96, 30, self.kern_size, \n",
    "                               stride=self.kern_stride, padding=self.kern_padding)\n",
    "        self._update_output_size()\n",
    "        \n",
    "        self.linearWidth = 30*int(self.width)*int(self.width)\n",
    "        self.fc1 = nn.Linear(self.linearWidth, 512)\n",
    "        self.fc2 = nn.Linear(512, 16)\n",
    "        self.fc3 = nn.Linear(16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "        x = self.pool4(F.relu(self.conv4(x)))\n",
    "        x = x.view(-1, self.linearWidth)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def _update_output_size(self):       \n",
    "        temp = self.width\n",
    "        self.width = ((self.width - self.kern_size + 2 * self.kern_padding) / self.kern_stride) + 1\n",
    "        temp1 = self.width\n",
    "        self.width = ((self.width - self.mxp_kern_size)/self.mxp_stride) + 1\n",
    "        print('Output width[ ' + str(temp) + ' -conv-> ' + str(temp1) + ' -maxpool-> ' + str(self.width) + ' ]')\n",
    "\n",
    "width = patch_size\n",
    "channels = 1\n",
    "net = Net(width, channels)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 4355358 patches found.\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "        imgutil.whiten_image2d,\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(40),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "trainset = PatchesGenerator(Dirs=Dirs, train_image_size=(patch_size, patch_size), \n",
    "                                 transform=transform,\n",
    "                                 fget_mask=get_mask_file, \n",
    "                                 fget_truth=get_ground_truth_file) \n",
    "\n",
    "### Fix skewed classes by sampling based on class weights\n",
    "labels = np.array(trainset.IDs)[:,3]\n",
    "_, ccounts_train = np.unique(labels, return_counts=True)\n",
    "cweights_train = 1.0/ccounts_train\n",
    "dweights_train = np.array([cweights_train[t] for t in labels])\n",
    "\n",
    "train_size = trainset.__len__() if train_size is None else train_size\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, \n",
    "                                          shuffle=False, num_workers=3, \n",
    "                                          sampler=WeightedRandomSampler(dweights_train, train_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 652750 patches found.\n"
     ]
    }
   ],
   "source": [
    "transform_val = transforms.Compose([\n",
    "        imgutil.whiten_image2d,\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "validation_set = PatchesGenerator(Dirs=ValidationDirs, train_image_size=(patch_size, patch_size), \n",
    "                                       transform=transform_val,\n",
    "                                       fget_mask=get_mask_file_test, \n",
    "                                       fget_truth=get_ground_truth_file) \n",
    "\n",
    "labels_val = np.array(validation_set.IDs)[:,3]\n",
    "_, ccounts_val = np.unique(labels_val, return_counts=True)\n",
    "cweights_val = 1.0/ccounts_val\n",
    "dweights_val = np.array([cweights_val[t] for t in labels_val])\n",
    "\n",
    "validation_size = validation_set.__len__() if validation_size is None else validation_size\n",
    "validationloader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size, \n",
    "                                            shuffle=False, num_workers=3,\n",
    "                                            sampler=WeightedRandomSampler(dweights_val, \n",
    "                                                                          validation_size, replacement=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epochs:[1/2] Batches:[200/962]  LOSS:0.319 precision:0.883 recall:0.855 f1:0.869 supp:0.000\n",
      "Epochs:[1/2] Batches:[239/962]  LOSS:0.286 precision:0.903 recall:0.933 f1:0.918 supp:0.000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-34:\n",
      "Process Process-35:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-36:\n",
      "  File \"/home/ak/anaconda/envs/ature_env/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ak/anaconda/envs/ature_env/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ak/anaconda/envs/ature_env/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ak/anaconda/envs/ature_env/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ak/anaconda/envs/ature_env/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/ak/anaconda/envs/ature_env/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ak/anaconda/envs/ature_env/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ak/anaconda/envs/ature_env/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/ak/anaconda/envs/ature_env/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/ak/anaconda/envs/ature_env/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/ak/anaconda/envs/ature_env/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/ak/anaconda/envs/ature_env/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/ak/anaconda/envs/ature_env/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/ak/anaconda/envs/ature_env/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/ak/anaconda/envs/ature_env/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/ak/anaconda/envs/ature_env/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/ak/anaconda/envs/ature_env/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/ak/anaconda/envs/ature_env/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/ak/anaconda/envs/ature_env/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ak/anaconda/envs/ature_env/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ak/anaconda/envs/ature_env/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs:[1/2] Batches:[240/962]  LOSS:0.374 precision:0.852 recall:0.920 f1:0.885 supp:0.000\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-3f31de8c8707>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# trainer.resume_from_checkpoint()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m trainer.train(optimizer=optimizer, dataloader=trainloader, epochs=epochs, use_gpu=use_gpu, \n\u001b[0;32m----> 4\u001b[0;31m               validationloader=validationloader)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# trainer.resume_from_checkpoint()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Spring2018/ature/neuralnet/torchtrainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, optimizer, dataloader, epochs, use_gpu, log_frequency, validationloader)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ature_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-5a09e8c6e154>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ature_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ature_env/lib/python3.6/site-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    140\u001b[0m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[1;32m    141\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                             self.return_indices)\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ature_env/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmax_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool2d\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \"\"\"\n\u001b[0;32m--> 360\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_indices\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "trainer = SimpleNNTrainer(model=net, checkpoint_dir=Dirs['checkpoint'], checkpoint_file=checkpoint_file)\n",
    "# trainer.resume_from_checkpoint()\n",
    "trainer.train(optimizer=optimizer, dataloader=trainloader, epochs=epochs, use_gpu=use_gpu, \n",
    "              validationloader=validationloader)\n",
    "# trainer.resume_from_checkpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on a image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 218063 patches found.\n"
     ]
    }
   ],
   "source": [
    "transform_test = transforms.Compose([\n",
    "        imgutil.whiten_image2d,\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "testset = PatchesGenerator(Dirs=TestDirs, train_image_size=(patch_size, patch_size), \n",
    "                                transform=transform_test,\n",
    "                                fget_mask=get_mask_file_test, \n",
    "                                fget_truth=get_ground_truth_file,\n",
    "                                segment_mode=True) \n",
    "\n",
    "sampler=WeightedRandomSampler(np.ones(testset.__len__()), 5000, replacement=False)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, \n",
    "                                          shuffle=False, num_workers=3, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n",
      "_________F1___of___batch[50/50]: 0.73\n",
      "Final F1: 0.61\n"
     ]
    }
   ],
   "source": [
    "IDs, IJs, scores, y_pred, y_true = trainer.evaluate(dataloader=testloader, use_gpu=use_gpu, force_checkpoint=False)\n",
    "# mnt.plot_confusion_matrix(y_pred=y_pred, y_true=y_true, classes=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolve throughout the image to generate segmented image based on trained Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = np.exp(scores.copy())\n",
    "seg = np.zeros(testset.images[0].working_arr.shape)\n",
    "for val in zip(IDs, IJs, sc):\n",
    "    image_id, (i, j), (b_prob, v_prob) = val\n",
    "    seg[i, j] = 255 * v_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=565x584 at 0x7F1E15E8A5C0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG.fromarray(seg.astype(np.uint8))#.save(checkpoint_file+testset.images[0].file_name+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# params = {'sk_threshold': 150,\n",
    "#           'alpha': 7.0,\n",
    "#           'orig_contrib': 0.3,\n",
    "#           'seg_threshold': 24}\n",
    "\n",
    "# img_obj = SegmentedImage()\n",
    "\n",
    "# img_obj.load_file(data_dir=TestDirs['images'], file_name=testset.images[0].file_name)\n",
    "# img_obj.res['orig'] = img_obj.image_arr[:, :, 1]\n",
    "# # img_obj.working_arr = 255 - seg.astype(np.uint8)\n",
    "\n",
    "# img_obj.load_mask(mask_dir=TestDirs['mask'], fget_mask=get_mask_file_test, erode=True)\n",
    "# img_obj.load_ground_truth(gt_dir=TestDirs['truth'], fget_ground_truth=get_ground_truth_file)\n",
    "\n",
    "# img_obj.generate_skeleton(threshold=params['sk_threshold'])\n",
    "# img_obj.generate_lattice_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tester = AtureTest(out_dir='')\n",
    "# tester.run(params=params, save_images=False, img_obj=img_obj)\n",
    "# img_obj.res['scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ature_env",
   "language": "python",
   "name": "ature_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
