{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import PIL.Image as IMG\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Other imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir('/home/ak/Spring2018/ature')\n",
    "\n",
    "from neuralnet.utils.torch_dataset import TorchPatchesGenerator\n",
    "from utils import img_utils as imgutil\n",
    "from commons.IMAGE import Image\n",
    "from neuralnet.torchtrainer import NNTrainer\n",
    "import neuralnet.utils.measurements as mnt\n",
    "import neuralnet.utils.data_utils as nndutils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define folders. Create if needed.\n",
    "sep = os.sep\n",
    "Dirs = {}\n",
    "Dirs['checkpoint']   = 'assests' +sep+ 'nnet_models'\n",
    "Dirs['data']      = 'data'+sep+'DRIVE'+sep+'training'\n",
    "Dirs['images']    = Dirs['data'] +sep+ 'images'\n",
    "Dirs['mask']      = Dirs['data'] +sep+ 'mask'\n",
    "Dirs['truth']     = Dirs['data'] +sep+ '1st_manual'\n",
    "\n",
    "TestDirs = {}\n",
    "TestDirs['data']      = 'data'+sep+'DRIVE'+sep+'test'\n",
    "TestDirs['images']    = TestDirs['data'] +sep+ 'test_images'\n",
    "TestDirs['mask']      = TestDirs['data'] +sep+ 'mask'\n",
    "TestDirs['truth']     = TestDirs['data'] +sep+ '1st_manual'\n",
    "\n",
    "ValidationDirs = {}\n",
    "ValidationDirs['data']      = 'data'+sep+'DRIVE'+sep+'test'\n",
    "ValidationDirs['images']    = ValidationDirs['data'] +sep+ 'validation_images'\n",
    "ValidationDirs['mask']      = ValidationDirs['data'] +sep+ 'mask'\n",
    "ValidationDirs['truth']     = ValidationDirs['data'] +sep+ '1st_manual'\n",
    "\n",
    "for k, folder in Dirs.items():\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "for k, folder in TestDirs.items():\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "for k, folder in ValidationDirs.items():\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "def get_mask_file(file_name): \n",
    "    return file_name.split('_')[0] + '_training_mask.gif'\n",
    "\n",
    "def get_ground_truth_file(file_name): \n",
    "    return file_name.split('_')[0] + '_manual1.gif'\n",
    "\n",
    "def get_mask_file_test(file_name): \n",
    "    return file_name.split('_')[0] + '_test_mask.gif'\n",
    "\n",
    "classes = { 'background': 0, 'vessel': 1,}\n",
    "batch_size = 52\n",
    "num_classes = len(classes)\n",
    "epochs = 10\n",
    "patch_size = 31\n",
    "use_gpu = False\n",
    "\n",
    "#### Images to train/validate per epoch ####\n",
    "train_size = 15000\n",
    "validation_size = None\n",
    "checkpoint_file = 'PytorchCheckpoint.nn.tar'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, width, channels):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.channels = channels\n",
    "        self.width = width\n",
    "    \n",
    "        self.kern_size = 5\n",
    "        self.kern_stride = 2      \n",
    "        self.kern_padding = 2\n",
    "        self.mxp_kern_size = 1\n",
    "        self.mxp_stride = 1 \n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=self.mxp_kern_size, stride=self.mxp_stride)\n",
    "        self.conv1 = nn.Conv2d(self.channels, 24, self.kern_size, \n",
    "                               stride=self.kern_stride, padding=self.kern_padding)\n",
    "        self._update_output_size()\n",
    "        \n",
    "        self.kern_size = 3\n",
    "        self.kern_stride = 1      \n",
    "        self.kern_padding = 1\n",
    "        self.mxp_kern_size = 1\n",
    "        self.mxp_stride = 1 \n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=self.mxp_kern_size, stride=self.mxp_stride)\n",
    "        self.conv2 = nn.Conv2d(24, 52, self.kern_size, \n",
    "                               stride=self.kern_stride, padding=self.kern_padding)\n",
    "        self._update_output_size()\n",
    "        \n",
    "        self.kern_size = 5\n",
    "        self.kern_stride = 1      \n",
    "        self.kern_padding = 2\n",
    "        self.mxp_kern_size = 2\n",
    "        self.mxp_stride = 2 \n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=self.mxp_kern_size, stride=self.mxp_stride)\n",
    "        self.conv3 = nn.Conv2d(52, 96, self.kern_size, \n",
    "                               stride=self.kern_stride, padding=self.kern_padding)\n",
    "        self._update_output_size()\n",
    "        \n",
    "        self.kern_size = 3\n",
    "        self.kern_stride = 1      \n",
    "        self.kern_padding = 1\n",
    "        self.mxp_kern_size = 1\n",
    "        self.mxp_stride = 1 \n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=self.mxp_kern_size, stride=self.mxp_stride)\n",
    "        self.conv4 = nn.Conv2d(96, 30, self.kern_size, \n",
    "                               stride=self.kern_stride, padding=self.kern_padding)\n",
    "        self._update_output_size()\n",
    "        \n",
    "        self.linearWidth = 30*int(self.width)*int(self.width)\n",
    "        self.fc1 = nn.Linear(self.linearWidth, 512)\n",
    "        self.fc2 = nn.Linear(512, 16)\n",
    "        self.fc3 = nn.Linear(16, num_classes)\n",
    "        self.sm = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = F.dropout(x, training=self.training, p=0.2)\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "        x = F.dropout(x, training=self.training, p=0.3)\n",
    "        x = self.pool4(F.relu(self.conv4(x)))\n",
    "        x = x.view(-1, self.linearWidth)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, training=self.training, p=0.2)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def _update_output_size(self):       \n",
    "        temp = self.width\n",
    "        self.width = ((self.width - self.kern_size + 2 * self.kern_padding) / self.kern_stride) + 1\n",
    "        temp1 = self.width\n",
    "        self.width = ((self.width - self.mxp_kern_size)/self.mxp_stride) + 1\n",
    "        print('Output width[ ' + str(temp) + ' -conv-> ' + str(temp1) + ' -maxpool-> ' + str(self.width) + ' ]')\n",
    "\n",
    "width = 31\n",
    "channels = 1\n",
    "net = Net(width, channels)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        imgutil.whiten_image2d,\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(40),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "trainset = TorchPatchesGenerator(Dirs=Dirs, patch_size=patch_size, \n",
    "                                 transform=transform,\n",
    "                                 fget_mask=get_mask_file, \n",
    "                                 fget_truth=get_ground_truth_file) \n",
    "\n",
    "### Fix skewed classes by sampling based on class weights\n",
    "labels = np.array(trainset.IDs)[:,3]\n",
    "_, ccounts_train = np.unique(labels, return_counts=True)\n",
    "cweights_train = 1.0/ccounts_train\n",
    "dweights_train = np.array([cweights_train[t] for t in labels])\n",
    "\n",
    "train_size = trainset.__len__() if train_size is None else train_size\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, \n",
    "                                          shuffle=False, num_workers=3, \n",
    "                                          sampler=WeightedRandomSampler(dweights_train, train_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = transforms.Compose([\n",
    "        imgutil.whiten_image2d,\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "validation_set = TorchPatchesGenerator(Dirs=ValidationDirs, patch_size=patch_size, \n",
    "                                       transform=transform_test,\n",
    "                                       fget_mask=get_mask_file_test, \n",
    "                                       fget_truth=get_ground_truth_file) \n",
    "\n",
    "labels_val = np.array(validation_set.IDs)[:,3]\n",
    "_, ccounts_val = np.unique(labels_val, return_counts=True)\n",
    "cweights_val = 1.0/ccounts_val\n",
    "dweights_val = np.array([cweights_val[t] for t in labels_val])\n",
    "\n",
    "validation_size = validation_set.__len__() if validation_size is None else validation_size\n",
    "validationloader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size, \n",
    "                                            shuffle=False, num_workers=3,\n",
    "                                            sampler=WeightedRandomSampler(dweights_val, \n",
    "                                                                          validation_size, replacement=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 216778 patches found.\n"
     ]
    }
   ],
   "source": [
    "testset = TorchPatchesGenerator(Dirs=TestDirs, patch_size=patch_size, \n",
    "                                transform=transform_test,\n",
    "                                fget_mask=get_mask_file_test, \n",
    "                                fget_truth=get_ground_truth_file,\n",
    "                                segment_mode=False) \n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=500, \n",
    "                                          shuffle=False, num_workers=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full',)).History will not be written to the database.\n",
      "Resumed from last checkpoint: PytorchCheckpoint.nn.tar\n",
      "Net(\n",
      "  (pool1): MaxPool2d(kernel_size=(1, 1), stride=(1, 1), dilation=(1, 1), ceil_mode=False)\n",
      "  (conv1): Conv2d(1, 24, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "  (pool2): MaxPool2d(kernel_size=(1, 1), stride=(1, 1), dilation=(1, 1), ceil_mode=False)\n",
      "  (conv2): Conv2d(24, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
      "  (conv3): Conv2d(52, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool4): MaxPool2d(kernel_size=(1, 1), stride=(1, 1), dilation=(1, 1), ceil_mode=False)\n",
      "  (conv4): Conv2d(96, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=1920, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=16, bias=True)\n",
      "  (fc3): Linear(in_features=16, out_features=2, bias=True)\n",
      "  (sm): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "trainer = NNTrainer(model=net, checkpoint_dir=Dirs['checkpoint'], checkpoint_file=checkpoint_file)\n",
    "trainer.resume_from_checkpoint()\n",
    "# trainer.train(optimizer=optimizer, dataloader=trainloader, epochs=epochs, use_gpu=use_gpu, \n",
    "#               validationloader=validationloader)\n",
    "# trainer.resume_from_checkpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check per-class performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "testloader.segment_mode = False\n",
    "acc, y_pred, y_true = trainer.test(dataloader=testloader, use_gpu=use_gpu, force_checkpoint=False)\n",
    "print(classification_report(y_true=y_true, y_pred=y_pred))\n",
    "mnt.plot_confusion_matrix(y_pred=y_pred, y_true=y_true, classes=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolve throughout the image to generate segmented image based on trained Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = np.zeros_like(testset.images[0].working_arr)\n",
    "testloader.segment_mode = True\n",
    "testloader.batch_size = 1\n",
    "for (ID, i, j, _), image, _ in testloader:\n",
    "    outputs = trainer.model(Variable(image))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    if predicted[0]==classes['vessel']:\n",
    "        seg[i, j] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=565x584 at 0x7FE4AD0DE4A8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG.fromarray(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ature_env",
   "language": "python",
   "name": "ature_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
