{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import PIL.Image as IMG\n",
    "\n",
    "# Other imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# NOTE: Aashis, you should use the training images to develop your algorithm.\n",
    "# The test images should be reserved for validating its performance afterwards\n",
    "# os.chdir('/home/ak/Spring2018/ature')\n",
    "os.chdir('/home/akhanal1/Spring2018/ature')\n",
    "\n",
    "sep = os.sep\n",
    "\n",
    "# Define folders (create them if needed)\n",
    "Dirs = {}\n",
    "Dirs['train_data']      = 'data'+sep+'DRIVE'+sep+'training'+sep +'patches'\n",
    "Dirs['test_data']      = 'data'+sep+'DRIVE'+sep+'test'+sep +'patches'\n",
    "\n",
    "# Set up execution flags\n",
    "Flags = {}\n",
    "Flags['useGPU'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DriveDataset(Dataset):\n",
    "    \n",
    "    ## INPUT\n",
    "    # data_path should contain pickled numpy array of dimension N * (D+1)\n",
    "    # Where extra one dimension stores the correct lable among (0, 1, 2, 3)\n",
    "    \n",
    "    ## self.target contains one-hot encoding\n",
    "    ## self.labels contains true labels (single value)\n",
    "    \n",
    "    def __init__(self, data_path=None, height=None, width=None, transform=None, load_one=False):\n",
    "        \n",
    "        self.data = None\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.transform = transform\n",
    "        \n",
    "        for data_file in os.listdir(data_path):\n",
    "            \n",
    "            data_file = os.path.join(data_path, data_file)\n",
    "            print('Data file: ' + data_file)\n",
    "            if self.data is None:\n",
    "                self.data = np.load(data_file)\n",
    "            else:\n",
    "                self.data = np.concatenate((self.data, np.load(data_file)), axis=0)\n",
    "            \n",
    "            if load_one:\n",
    "                break\n",
    "    \n",
    "        self.data_len = self.data.shape[0]\n",
    "        \n",
    "        self.target = np.zeros((self.data_len, 4))\n",
    "        self.labels = self.data[:, self.height * self.width] \n",
    "        self.target[range(self.data_len), self.labels] = 1\n",
    "        \n",
    "        self.data = self.data[:,0:self.height * self.width]\n",
    "        self.labels = torch.from_numpy(self.labels)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        a_data = self.data[index]\n",
    "        img_arr = a_data.reshape(self.height, self.width)\n",
    "        img = IMG.fromarray(img_arr)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img_tensor = self.transform(img)\n",
    "            \n",
    "        return (img_tensor, self.labels[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file: data/DRIVE/training/patches/26_training.npy\n",
      "Data file: data/DRIVE/test/patches/19_test.npy\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "trainset = DriveDataset(data_path=Dirs['train_data'], height=31, width=31, transform=transform, load_one=True)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=2,\n",
    "                                          shuffle=True, num_workers=1)\n",
    "testset = DriveDataset(data_path=Dirs['test_data'], height=31, width=31, transform=transform, load_one=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=2,\n",
    "                                          shuffle=True, num_workers=1)\n",
    "\n",
    "classes = ('white', 'green', 'black', 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAB8AAAAfCAAAAAA6xUnlAAABzklEQVR4nCXR0aEDRwwCQEDa86Wi9N/Vs1eCfGRaGP77VBQKRGjQFML8jTlLNQEGFJIQAZEZJzslp7of2hKddRGDwPOLfLfF06eioEA6yzN3DeQuT1nv07hUhQGR4DuAzavq+pR6ugYLTji7NytbTJdaRYX9hcTyd9fh7jwnEQkSANDF2vVfxuKsKvO2gYgGwE7uXXqKfzxEPWRzDDAE07OeJZQ06i0USR6PHQXq7yCC5zmocj4CvKqAIM3mm1mf91Ql0Bo5+muUhMh9Jz6f6ocbZAPWoF3IhFK735wuglp3GK+ISqqSRb+t1PMT/H+i7ZBklSFNVx9o2+ispyAScEtEhKf/KQGX8hdVF4hJRiQUOn3kJEl9PBDCohCKBCX3FAGo9ka0GDLxKSQw0KJNyW5lislGJLVOQDedgVhyDI4AgkxsAVQPwuRuACcICu3BKqvONOUBCCzEBZ/83MRQnLTaMShYHYTF8PUQCBqwGiZEgGVXZaSxBJiAuC0AcYCNtBYWD82FCqrbCQDUbj+cUdkfjBms6KATkAQDedA+NZZwFiGcjoiNXszP/EytTxwY1XeRFgUJm1CEAKBco4xtsYNqLxNApMOyEw48rZ/+A9LTgRikSy45AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=31x31 at 0x7F01C0A7D5F8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG.fromarray(trainset.data[10000].reshape(31,31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186895, 961)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, width):\n",
    "        super(Net, self).__init__()\n",
    "        nChannels = 1\n",
    "        convKernelSize = 3\n",
    "        convStride = 1\n",
    "        mpKernelSize = 2\n",
    "        mpStride = 2        \n",
    "        padding = 0\n",
    "        dilation = 1\n",
    "\n",
    "        self.pool = nn.MaxPool2d(mpStride)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(nChannels, 6, convKernelSize)\n",
    "        width = self.output_size(width,convKernelSize,padding,dilation,\n",
    "            mpKernelSize,mpStride)\n",
    "        self.conv2 = nn.Conv2d(6, 16, convKernelSize)\n",
    "        width = self.output_size(width,convKernelSize,padding,dilation,\n",
    "            mpKernelSize,mpStride)\n",
    "\n",
    "        self.linearWidth = 16*int(width)*int(width)\n",
    "        self.fc1 = nn.Linear(self.linearWidth, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 4)\n",
    "        self.sm = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, self.linearWidth)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    # Output size of a convolution, followed by max pooling operation\n",
    "    def output_size(self,inputSize,convKernelSize,padding,dilation,\n",
    "                    kernelSize,stride):\n",
    "        return np.floor(((inputSize - 2*np.floor(convKernelSize/2)) + \n",
    "                        2*padding - dilation*(kernelSize-1) - 1) / stride + 1)\n",
    "\n",
    "width = 31\n",
    "net = Net(width)\n",
    "\n",
    "# Send network to the GPU, if requested\n",
    "if Flags['useGPU']:\n",
    "    net.cuda()\n",
    "\n",
    "# Define loss criterion\n",
    "# criterion = nn.L1Loss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(2): \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        if Flags['useGPU']:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())                \n",
    "        else:                \n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 50 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    \n",
    "    images, labels = data  \n",
    "    if Flags['useGPU']:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check per-class performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "for data in testloader:\n",
    "    \n",
    "    images, labels = data\n",
    "    \n",
    "    if Flags['useGPU']:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    for i in range(4):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(169795, 2601)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ature",
   "language": "python",
   "name": "pl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
