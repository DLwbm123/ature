{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import PIL.Image as IMG\n",
    "\n",
    "# Other imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# NOTE: Aashis, you should use the training images to develop your algorithm.\n",
    "# The test images should be reserved for validating its performance afterwards\n",
    "# os.chdir('/home/ak/Spring2018/ature')\n",
    "os.chdir('/home/akhanal1/Spring2018/ature')\n",
    "\n",
    "sep = os.sep\n",
    "\n",
    "# Define folders (create them if needed)\n",
    "Dirs = {}\n",
    "Dirs['train_data']      = 'data'+sep+'DRIVE'+sep+'training'+sep +'patches'\n",
    "Dirs['test_data']      = 'data'+sep+'DRIVE'+sep+'test'+sep +'patches'\n",
    "\n",
    "# Set up execution flags\n",
    "Flags = {}\n",
    "Flags['useGPU'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DriveDataset(Dataset):\n",
    "    \n",
    "    ## INPUT\n",
    "    # data_path should contain pickled numpy array of dimension N * (D+1)\n",
    "    # Where extra one dimension stores the correct lable among (0, 1, 2, 3)\n",
    "    \n",
    "    ## self.labels contains one-hot encoding\n",
    "    ## self.target contains true labels (single value)\n",
    "    \n",
    "    def __init__(self, data_path=None, height=None, width=None, transform=None, load_one=False):\n",
    "        \n",
    "        self.data = None\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.transform = transform\n",
    "        \n",
    "        for data_file in os.listdir(data_path):\n",
    "            \n",
    "            data_file = os.path.join(data_path, data_file)\n",
    "            print('Data file: ' + data_file)\n",
    "            if self.data is None:\n",
    "                self.data = np.load(data_file)\n",
    "            else:\n",
    "                self.data = np.concatenate((self.data, np.load(data_file)), axis=0)\n",
    "            \n",
    "            if load_one:\n",
    "                break\n",
    "    \n",
    "        self.data_len = self.data.shape[0]\n",
    "        \n",
    "        self.labels = np.zeros((self.data_len, 4))\n",
    "        self.target = self.data[:, self.height * self.width] \n",
    "        self.labels[range(self.data_len), self.target] = 1\n",
    "        \n",
    "        self.data = self.data[:,0:self.height * self.width]\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        a_data = self.data[index]\n",
    "        img_arr = a_data.reshape(self.height, self.width)\n",
    "        img = IMG.fromarray(img_arr)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img_tensor = self.transform(img)\n",
    "#             \n",
    "#         return (img_tensor, torch.LongTensor(self.target[index]))\n",
    "        return (img_tensor, torch.from_numpy(self.labels[index])) \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file: data/DRIVE/training/patches/26_training.npy\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "trainset = DriveDataset(data_path=Dirs['train_data'], height=31, width=31, transform=transform, load_one=True)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=2,\n",
    "                                          shuffle=True, num_workers=1)\n",
    "testset = DriveDataset(data_path=Dirs['test_data'], height=31, width=31, transform=transform, load_one=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=2,\n",
    "                                          shuffle=True, num_workers=1)\n",
    "\n",
    "classes = ('white', 'green', 'black', 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAB8AAAAfCAAAAAA6xUnlAAABzklEQVR4nCXR0aEDRwwCQEDa86Wi9N/Vs1eCfGRaGP77VBQKRGjQFML8jTlLNQEGFJIQAZEZJzslp7of2hKddRGDwPOLfLfF06eioEA6yzN3DeQuT1nv07hUhQGR4DuAzavq+pR6ugYLTji7NytbTJdaRYX9hcTyd9fh7jwnEQkSANDF2vVfxuKsKvO2gYgGwE7uXXqKfzxEPWRzDDAE07OeJZQ06i0USR6PHQXq7yCC5zmocj4CvKqAIM3mm1mf91Ql0Bo5+muUhMh9Jz6f6ocbZAPWoF3IhFK735wuglp3GK+ISqqSRb+t1PMT/H+i7ZBklSFNVx9o2+ispyAScEtEhKf/KQGX8hdVF4hJRiQUOn3kJEl9PBDCohCKBCX3FAGo9ka0GDLxKSQw0KJNyW5lislGJLVOQDedgVhyDI4AgkxsAVQPwuRuACcICu3BKqvONOUBCCzEBZ/83MRQnLTaMShYHYTF8PUQCBqwGiZEgGVXZaSxBJiAuC0AcYCNtBYWD82FCqrbCQDUbj+cUdkfjBms6KATkAQDedA+NZZwFiGcjoiNXszP/EytTxwY1XeRFgUJm1CEAKBco4xtsYNqLxNApMOyEw48rZ/+A9LTgRikSy45AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=31x31 at 0x7F0F61033780>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG.fromarray(trainset.data[10000].reshape(31,31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186895, 961)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, width):\n",
    "        super(Net, self).__init__()\n",
    "        nChannels = 1\n",
    "        convKernelSize = 3\n",
    "        convStride = 1\n",
    "        mpKernelSize = 2\n",
    "        mpStride = 2        \n",
    "        padding = 0\n",
    "        dilation = 1\n",
    "\n",
    "        self.pool = nn.MaxPool2d(mpStride)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(nChannels, 6, convKernelSize)\n",
    "        width = self.output_size(width,convKernelSize,padding,dilation,\n",
    "            mpKernelSize,mpStride)\n",
    "        self.conv2 = nn.Conv2d(6, 16, convKernelSize)\n",
    "        width = self.output_size(width,convKernelSize,padding,dilation,\n",
    "            mpKernelSize,mpStride)\n",
    "\n",
    "        self.linearWidth = 16*int(width)*int(width)\n",
    "        self.fc1 = nn.Linear(self.linearWidth, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 4)\n",
    "        self.sm = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, self.linearWidth)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    # Output size of a convolution, followed by max pooling operation\n",
    "    def output_size(self,inputSize,convKernelSize,padding,dilation,\n",
    "                    kernelSize,stride):\n",
    "        return np.floor(((inputSize - 2*np.floor(convKernelSize/2)) + \n",
    "                        2*padding - dilation*(kernelSize-1) - 1) / stride + 1)\n",
    "\n",
    "width = 31\n",
    "net = Net(width)\n",
    "\n",
    "# Send network to the GPU, if requested\n",
    "if Flags['useGPU']:\n",
    "    net.cuda()\n",
    "\n",
    "# Define loss criterion\n",
    "# criterion = nn.L1Loss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.742\n",
      "[1,  4000] loss: 0.699\n",
      "[1,  6000] loss: 0.701\n",
      "[1,  8000] loss: 0.661\n",
      "[1, 10000] loss: 0.684\n",
      "[1, 12000] loss: 0.676\n",
      "[1, 14000] loss: 0.717\n",
      "[1, 16000] loss: 0.708\n",
      "[1, 18000] loss: 0.666\n",
      "[1, 20000] loss: 0.671\n",
      "[1, 22000] loss: 0.666\n",
      "[1, 24000] loss: 0.679\n",
      "[1, 26000] loss: 0.673\n",
      "[1, 28000] loss: 0.670\n",
      "[1, 30000] loss: 0.665\n",
      "[1, 32000] loss: 0.530\n",
      "[1, 34000] loss: 0.506\n",
      "[1, 36000] loss: 0.466\n",
      "[1, 38000] loss: 0.470\n",
      "[1, 40000] loss: 0.423\n",
      "[1, 42000] loss: 0.413\n",
      "[1, 44000] loss: 0.398\n",
      "[1, 46000] loss: 0.375\n",
      "[1, 48000] loss: 0.352\n",
      "[1, 50000] loss: 0.392\n",
      "[1, 52000] loss: 0.366\n",
      "[1, 54000] loss: 0.357\n",
      "[1, 56000] loss: 0.349\n",
      "[1, 58000] loss: 0.351\n",
      "[1, 60000] loss: 0.364\n",
      "[1, 62000] loss: 0.363\n",
      "[1, 64000] loss: 0.328\n",
      "[1, 66000] loss: 0.325\n",
      "[1, 68000] loss: 0.329\n",
      "[1, 70000] loss: 0.307\n",
      "[1, 72000] loss: 0.316\n",
      "[1, 74000] loss: 0.329\n",
      "[1, 76000] loss: 0.323\n",
      "[1, 78000] loss: 0.322\n",
      "[1, 80000] loss: 0.306\n",
      "[1, 82000] loss: 0.315\n",
      "[1, 84000] loss: 0.319\n",
      "[1, 86000] loss: 0.313\n",
      "[1, 88000] loss: 0.290\n",
      "[1, 90000] loss: 0.301\n",
      "[1, 92000] loss: 0.301\n",
      "[2,  2000] loss: 0.305\n",
      "[2,  4000] loss: 0.283\n",
      "[2,  6000] loss: 0.280\n",
      "[2,  8000] loss: 0.298\n",
      "[2, 10000] loss: 0.295\n",
      "[2, 12000] loss: 0.298\n",
      "[2, 14000] loss: 0.285\n",
      "[2, 16000] loss: 0.261\n",
      "[2, 18000] loss: 0.286\n",
      "[2, 20000] loss: 0.287\n",
      "[2, 22000] loss: 0.296\n",
      "[2, 24000] loss: 0.297\n",
      "[2, 26000] loss: 0.295\n",
      "[2, 28000] loss: 0.293\n",
      "[2, 30000] loss: 0.269\n",
      "[2, 32000] loss: 0.288\n",
      "[2, 34000] loss: 0.291\n",
      "[2, 36000] loss: 0.299\n",
      "[2, 38000] loss: 0.286\n",
      "[2, 40000] loss: 0.278\n",
      "[2, 42000] loss: 0.286\n",
      "[2, 44000] loss: 0.281\n",
      "[2, 46000] loss: 0.288\n",
      "[2, 48000] loss: 0.276\n",
      "[2, 50000] loss: 0.267\n",
      "[2, 52000] loss: 0.271\n",
      "[2, 54000] loss: 0.290\n",
      "[2, 56000] loss: 0.251\n",
      "[2, 58000] loss: 0.279\n",
      "[2, 60000] loss: 0.283\n",
      "[2, 62000] loss: 0.254\n",
      "[2, 64000] loss: 0.258\n",
      "[2, 66000] loss: 0.275\n",
      "[2, 68000] loss: 0.262\n",
      "[2, 70000] loss: 0.262\n",
      "[2, 72000] loss: 0.263\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        labels = labels.long()\n",
    "        labels = torch.max(labels,1)[1]\n",
    "\n",
    "\n",
    "        if Flags['useGPU']:\n",
    "            # Wrap them in Variable (CPU version)\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())                \n",
    "        else:                \n",
    "            # Wrap them in Variable (GPU version)\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "#         print(inputs, labels)\n",
    "#         break\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testloader' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-10c7a3033fbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mFlags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'useGPU'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'testloader' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data        \n",
    "    if Flags['useGPU']:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check per-class performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    if Flags['useGPU']:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    for i in range(4):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(169795, 2601)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ature",
   "language": "python",
   "name": "pl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
