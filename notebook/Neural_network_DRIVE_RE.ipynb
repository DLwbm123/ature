{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import PIL.Image as IMG\n",
    "\n",
    "# Other imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# NOTE: Aashis, you should use the training images to develop your algorithm.\n",
    "# The test images should be reserved for validating its performance afterwards\n",
    "# os.chdir('/home/ak/Spring2018/ature')\n",
    "os.chdir('/home/akhanal1/Spring2018/ature')\n",
    "\n",
    "sep = os.sep\n",
    "\n",
    "# Define folders (create them if needed)\n",
    "Dirs = {}\n",
    "Dirs['train_data']      = 'data'+sep+'DRIVE'+sep+'training'+sep +'patches'\n",
    "Dirs['test_data']      = 'data'+sep+'DRIVE'+sep+'test'+sep +'patches'\n",
    "\n",
    "# Set up execution flags\n",
    "Flags = {}\n",
    "Flags['useGPU'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DriveDataset(Dataset):\n",
    "    \n",
    "    ## INPUT\n",
    "    # data_path should contain pickled numpy array of dimension N * (D+1)\n",
    "    # Where extra one dimension stores the correct lable among (0, 1, 2, 3)\n",
    "    \n",
    "    ## self.target contains one-hot encoding\n",
    "    ## self.labels contains true labels (single value)\n",
    "    \n",
    "    def __init__(self, data_path=None, height=None, width=None, transform=None, load_one=False):\n",
    "        \n",
    "        self.data = None\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.transform = transform\n",
    "        \n",
    "        for data_file in os.listdir(data_path):\n",
    "            \n",
    "            data_file = os.path.join(data_path, data_file)\n",
    "            print('Data file: ' + data_file)\n",
    "            if self.data is None:\n",
    "                self.data = np.load(data_file)\n",
    "            else:\n",
    "                self.data = np.concatenate((self.data, np.load(data_file)), axis=0)\n",
    "            \n",
    "            if load_one:\n",
    "                break\n",
    "    \n",
    "        self.data_len = self.data.shape[0]\n",
    "        \n",
    "        self.target = np.zeros((self.data_len, 4))\n",
    "        self.labels = self.data[:, self.height * self.width] \n",
    "        self.target[range(self.data_len), self.labels] = 1\n",
    "        \n",
    "        self.data = self.data[:,0:self.height * self.width]\n",
    "        self.labels = torch.from_numpy(self.labels)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        a_data = self.data[index]\n",
    "        img_arr = a_data.reshape(self.height, self.width)\n",
    "        img = IMG.fromarray(img_arr)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img_tensor = self.transform(img)\n",
    "            \n",
    "        return (img_tensor, self.labels[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file: data/DRIVE/training/patches/26_training.npy\n",
      "Data file: data/DRIVE/test/patches/19_test.npy\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "trainset = DriveDataset(data_path=Dirs['train_data'], height=31, width=31, transform=transform, load_one=True)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=2,\n",
    "                                          shuffle=True, num_workers=1)\n",
    "testset = DriveDataset(data_path=Dirs['test_data'], height=31, width=31, transform=transform, load_one=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=2,\n",
    "                                          shuffle=True, num_workers=1)\n",
    "\n",
    "classes = ('white', 'green', 'black', 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAB8AAAAfCAAAAAA6xUnlAAABzklEQVR4nCXR0aEDRwwCQEDa86Wi9N/Vs1eCfGRaGP77VBQKRGjQFML8jTlLNQEGFJIQAZEZJzslp7of2hKddRGDwPOLfLfF06eioEA6yzN3DeQuT1nv07hUhQGR4DuAzavq+pR6ugYLTji7NytbTJdaRYX9hcTyd9fh7jwnEQkSANDF2vVfxuKsKvO2gYgGwE7uXXqKfzxEPWRzDDAE07OeJZQ06i0USR6PHQXq7yCC5zmocj4CvKqAIM3mm1mf91Ql0Bo5+muUhMh9Jz6f6ocbZAPWoF3IhFK735wuglp3GK+ISqqSRb+t1PMT/H+i7ZBklSFNVx9o2+ispyAScEtEhKf/KQGX8hdVF4hJRiQUOn3kJEl9PBDCohCKBCX3FAGo9ka0GDLxKSQw0KJNyW5lislGJLVOQDedgVhyDI4AgkxsAVQPwuRuACcICu3BKqvONOUBCCzEBZ/83MRQnLTaMShYHYTF8PUQCBqwGiZEgGVXZaSxBJiAuC0AcYCNtBYWD82FCqrbCQDUbj+cUdkfjBms6KATkAQDedA+NZZwFiGcjoiNXszP/EytTxwY1XeRFgUJm1CEAKBco4xtsYNqLxNApMOyEw48rZ/+A9LTgRikSy45AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=31x31 at 0x7FF1D489E978>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG.fromarray(trainset.data[10000].reshape(31,31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186895, 961)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, width):\n",
    "        super(Net, self).__init__()\n",
    "        nChannels = 1\n",
    "        convKernelSize = 3\n",
    "        convStride = 1\n",
    "        mpKernelSize = 2\n",
    "        mpStride = 2        \n",
    "        padding = 0\n",
    "        dilation = 1\n",
    "\n",
    "        self.pool = nn.MaxPool2d(mpStride)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(nChannels, 6, convKernelSize)\n",
    "        width = self.output_size(width,convKernelSize,padding,dilation,\n",
    "            mpKernelSize,mpStride)\n",
    "        self.conv2 = nn.Conv2d(6, 16, convKernelSize)\n",
    "        width = self.output_size(width,convKernelSize,padding,dilation,\n",
    "            mpKernelSize,mpStride)\n",
    "\n",
    "        self.linearWidth = 16*int(width)*int(width)\n",
    "        self.fc1 = nn.Linear(self.linearWidth, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 4)\n",
    "        self.sm = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, self.linearWidth)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    # Output size of a convolution, followed by max pooling operation\n",
    "    def output_size(self,inputSize,convKernelSize,padding,dilation,\n",
    "                    kernelSize,stride):\n",
    "        return np.floor(((inputSize - 2*np.floor(convKernelSize/2)) + \n",
    "                        2*padding - dilation*(kernelSize-1) - 1) / stride + 1)\n",
    "\n",
    "width = 31\n",
    "net = Net(width)\n",
    "\n",
    "# Send network to the GPU, if requested\n",
    "if Flags['useGPU']:\n",
    "    net.cuda()\n",
    "\n",
    "# Define loss criterion\n",
    "# criterion = nn.L1Loss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.716\n",
      "[1,  4000] loss: 0.689\n",
      "[1,  6000] loss: 0.705\n",
      "[1,  8000] loss: 0.676\n",
      "[1, 10000] loss: 0.658\n",
      "[1, 12000] loss: 0.683\n",
      "[1, 14000] loss: 0.661\n",
      "[1, 16000] loss: 0.702\n",
      "[1, 18000] loss: 0.660\n",
      "[1, 20000] loss: 0.672\n",
      "[1, 22000] loss: 0.600\n",
      "[1, 24000] loss: 0.502\n",
      "[1, 26000] loss: 0.536\n",
      "[1, 28000] loss: 0.481\n",
      "[1, 30000] loss: 0.457\n",
      "[1, 32000] loss: 0.431\n",
      "[1, 34000] loss: 0.422\n",
      "[1, 36000] loss: 0.404\n",
      "[1, 38000] loss: 0.392\n",
      "[1, 40000] loss: 0.393\n",
      "[1, 42000] loss: 0.388\n",
      "[1, 44000] loss: 0.374\n",
      "[1, 46000] loss: 0.363\n",
      "[1, 48000] loss: 0.370\n",
      "[1, 50000] loss: 0.365\n",
      "[1, 52000] loss: 0.371\n",
      "[1, 54000] loss: 0.362\n",
      "[1, 56000] loss: 0.357\n",
      "[1, 58000] loss: 0.330\n",
      "[1, 60000] loss: 0.325\n",
      "[1, 62000] loss: 0.327\n",
      "[1, 64000] loss: 0.327\n",
      "[1, 66000] loss: 0.312\n",
      "[1, 68000] loss: 0.338\n",
      "[1, 70000] loss: 0.313\n",
      "[1, 72000] loss: 0.302\n",
      "[1, 74000] loss: 0.324\n",
      "[1, 76000] loss: 0.314\n",
      "[1, 78000] loss: 0.314\n",
      "[1, 80000] loss: 0.293\n",
      "[1, 82000] loss: 0.299\n",
      "[1, 84000] loss: 0.322\n",
      "[1, 86000] loss: 0.300\n",
      "[1, 88000] loss: 0.293\n",
      "[1, 90000] loss: 0.294\n",
      "[1, 92000] loss: 0.310\n",
      "[2,  2000] loss: 0.277\n",
      "[2,  4000] loss: 0.291\n",
      "[2,  6000] loss: 0.283\n",
      "[2,  8000] loss: 0.288\n",
      "[2, 10000] loss: 0.297\n",
      "[2, 12000] loss: 0.290\n",
      "[2, 14000] loss: 0.287\n",
      "[2, 16000] loss: 0.265\n",
      "[2, 18000] loss: 0.282\n",
      "[2, 20000] loss: 0.298\n",
      "[2, 22000] loss: 0.270\n",
      "[2, 24000] loss: 0.282\n",
      "[2, 26000] loss: 0.265\n",
      "[2, 28000] loss: 0.259\n",
      "[2, 30000] loss: 0.258\n",
      "[2, 32000] loss: 0.285\n",
      "[2, 34000] loss: 0.281\n",
      "[2, 36000] loss: 0.287\n",
      "[2, 38000] loss: 0.280\n",
      "[2, 40000] loss: 0.279\n",
      "[2, 42000] loss: 0.278\n",
      "[2, 44000] loss: 0.271\n",
      "[2, 46000] loss: 0.271\n",
      "[2, 48000] loss: 0.271\n",
      "[2, 50000] loss: 0.255\n",
      "[2, 52000] loss: 0.281\n",
      "[2, 54000] loss: 0.260\n",
      "[2, 56000] loss: 0.256\n",
      "[2, 58000] loss: 0.253\n",
      "[2, 60000] loss: 0.261\n",
      "[2, 62000] loss: 0.268\n",
      "[2, 64000] loss: 0.259\n",
      "[2, 66000] loss: 0.271\n",
      "[2, 68000] loss: 0.291\n",
      "[2, 70000] loss: 0.263\n",
      "[2, 72000] loss: 0.271\n",
      "[2, 74000] loss: 0.272\n",
      "[2, 76000] loss: 0.265\n",
      "[2, 78000] loss: 0.259\n",
      "[2, 80000] loss: 0.254\n",
      "[2, 82000] loss: 0.248\n",
      "[2, 84000] loss: 0.265\n",
      "[2, 86000] loss: 0.280\n",
      "[2, 88000] loss: 0.252\n",
      "[2, 90000] loss: 0.256\n",
      "[2, 92000] loss: 0.263\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2): \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        if Flags['useGPU']:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())                \n",
    "        else:                \n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 2000 test images: 88 %\n",
      "Accuracy of 4000 test images: 89 %\n",
      "Accuracy of 6000 test images: 89 %\n",
      "Accuracy of 8000 test images: 89 %\n",
      "Accuracy of 10000 test images: 88 %\n",
      "Accuracy of 12000 test images: 88 %\n",
      "Accuracy of 14000 test images: 89 %\n",
      "Accuracy of 16000 test images: 88 %\n",
      "Accuracy of 18000 test images: 88 %\n",
      "Accuracy of 20000 test images: 88 %\n",
      "Accuracy of 22000 test images: 88 %\n",
      "Accuracy of 24000 test images: 88 %\n",
      "Accuracy of 26000 test images: 88 %\n",
      "Accuracy of 28000 test images: 88 %\n",
      "Accuracy of 30000 test images: 88 %\n",
      "Accuracy of 32000 test images: 88 %\n",
      "Accuracy of 34000 test images: 88 %\n",
      "Accuracy of 36000 test images: 88 %\n",
      "Accuracy of 38000 test images: 88 %\n",
      "Accuracy of 40000 test images: 88 %\n",
      "Accuracy of 42000 test images: 88 %\n",
      "Accuracy of 44000 test images: 88 %\n",
      "Accuracy of 46000 test images: 88 %\n",
      "Accuracy of 48000 test images: 88 %\n",
      "Accuracy of 50000 test images: 88 %\n",
      "Accuracy of 52000 test images: 88 %\n",
      "Accuracy of 54000 test images: 88 %\n",
      "Accuracy of 56000 test images: 88 %\n",
      "Accuracy of 58000 test images: 88 %\n",
      "Accuracy of 60000 test images: 88 %\n",
      "Accuracy of 62000 test images: 88 %\n",
      "Accuracy of 64000 test images: 88 %\n",
      "Accuracy of 66000 test images: 88 %\n",
      "Accuracy of 68000 test images: 88 %\n",
      "Accuracy of 70000 test images: 88 %\n",
      "Accuracy of 72000 test images: 88 %\n",
      "Accuracy of 74000 test images: 88 %\n",
      "Accuracy of 76000 test images: 88 %\n",
      "Accuracy of 78000 test images: 88 %\n",
      "Accuracy of 80000 test images: 88 %\n",
      "Accuracy of 82000 test images: 88 %\n",
      "Accuracy of 84000 test images: 88 %\n",
      "Accuracy of 86000 test images: 88 %\n",
      "Accuracy of 88000 test images: 88 %\n",
      "Accuracy of 90000 test images: 88 %\n",
      "Accuracy of 92000 test images: 88 %\n",
      "Accuracy of 94000 test images: 88 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    \n",
    "    images, labels = data  \n",
    "    if Flags['useGPU']:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "    if i % 2000 == 1999:\n",
    "        print('Accuracy of %d test images: %d %%' % (i+1, 100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check per-class performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(4))\n",
    "class_total = list(0. for i in range(4))\n",
    "i = 0\n",
    "for data in testloader:\n",
    "    \n",
    "    images, labels = data\n",
    "    \n",
    "    if Flags['useGPU']:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    for i in range(2):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "    i = i+1\n",
    "    if i > 10000:\n",
    "        break\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ature",
   "language": "python",
   "name": "pl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
