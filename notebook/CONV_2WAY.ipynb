{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import PIL.Image as IMG\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "# Other imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir('/home/ak/Spring2018/ature')\n",
    "from neuralnet.utils.datasets import  DriveDatasetFromFile, DriveDatasetFromImageObj\n",
    "\n",
    "from utils import img_utils as imgutil\n",
    "from commons.IMAGE import SegmentedImage\n",
    "\n",
    "sep = os.sep\n",
    "\n",
    "# Define folders (create them if needed)\n",
    "Dirs = {}\n",
    "Dirs['train_data']      = 'data'+sep+'DRIVE'+sep+'training'+sep +'patches'\n",
    "\n",
    "Dirs['data']      = 'data'+sep+'DRIVE'+sep+'test'\n",
    "Dirs['images']    = Dirs['data'] +sep+ 'images'\n",
    "Dirs['mask']      = Dirs['data'] +sep+ 'mask'\n",
    "Dirs['truth']     = Dirs['data'] +sep+ '1st_manual'\n",
    "Dirs['segmented'] = Dirs['data'] +sep+ 'drive_segmented'\n",
    "Dirs['test_data'] = Dirs['data'] +sep+ 'patches'\n",
    "\n",
    "def get_mask_file(file_name): \n",
    "    return file_name.split('_')[0] + '_test_mask.gif'\n",
    "\n",
    "def get_ground_truth_file(file_name): \n",
    "    return file_name.split('_')[0] + '_manual1.gif'\n",
    "\n",
    "input_image = '19_test.tif'\n",
    "\n",
    "# Set up execution flags\n",
    "Flags = {}\n",
    "Flags['useGPU'] = False\n",
    "\n",
    "classes = ('white', 'green', 'black', 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "trainset = DriveDatasetFromFile(data_path=Dirs['train_data'], height=31, width=31,\n",
    "                                num_classes=2, transform=transform)\n",
    "clss, class_counts = np.unique(trainset.labels, return_counts=True)\n",
    "class_weights = 1.0/class_counts\n",
    "data_weights = np.array([class_weights[t] for t in trainset.labels]) \n",
    "second_min_class_count =  np.partition(class_counts, 1)[1]\n",
    "\n",
    "sampler = WeightedRandomSampler(data_weights, int(second_min_class_count))\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=False, num_workers=1, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG.fromarray(trainset.data[3000].reshape(31,31))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, width, channels):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.channels = channels\n",
    "        self.width = width\n",
    "        \n",
    "        \n",
    "        self.kern_size = 5\n",
    "        self.kern_stride = 2      \n",
    "        self.kern_padding = 2\n",
    "        \n",
    "        self.mxp_kern_size = 2\n",
    "        self.mxp_stride = 2 \n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=self.mxp_kern_size, stride=self.mxp_stride)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(self.channels, 20, self.kern_size, \n",
    "                               stride=self.kern_stride, padding=self.kern_padding)\n",
    "        self._update_output_size()\n",
    "        \n",
    "        \n",
    "        self.kern_size = 5\n",
    "        self.kern_stride = 1      \n",
    "        self.kern_padding = 1\n",
    "        \n",
    "        self.mxp_kern_size = 1\n",
    "        self.mxp_stride = 1 \n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=self.mxp_kern_size, stride=self.mxp_stride)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(20, 50, self.kern_size, \n",
    "                               stride=self.kern_stride, padding=self.kern_padding)\n",
    "        self._update_output_size()\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.linearWidth = 50*int(self.width)*int(self.width)\n",
    "        self.fc1 = nn.Linear(self.linearWidth, 30)\n",
    "        self.fc2 = nn.Linear(30, 10)\n",
    "        self.fc3 = nn.Linear(10, 4)\n",
    "        self.sm = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, self.linearWidth)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def _update_output_size(self):       \n",
    "        self.width = ((self.width - self.kern_size + 2 * self.kern_padding) / self.kern_stride) + 1\n",
    "        temp = self.width\n",
    "        self.width = ((self.width - self.mxp_kern_size)/self.mxp_stride) + 1\n",
    "        print('output width { conv: ' + str(temp) + ', maxpool: ' + str(self.width) + ' }')\n",
    "\n",
    "width = 31\n",
    "channels = 1\n",
    "net = Net(width, channels)\n",
    "\n",
    "# Send network to the GPU, if requested\n",
    "if Flags['useGPU']:\n",
    "    net.cuda()\n",
    "\n",
    "# Define loss criterion\n",
    "# criterion = nn.L1Loss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(3): \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        if Flags['useGPU']:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())                \n",
    "        else:                \n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics every 500 mini-batches\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 1000 == 999:\n",
    "            print('[epoch: %d, batches: %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = DriveDatasetFromFile(data_path=Dirs['test_data'], height=31, width=31, \n",
    "                               transform=transform, num_classes=2)\n",
    "clss_test, class_counts_test = np.unique(testset.labels, return_counts=True)\n",
    "class_weights_test = 1.0/class_counts_test\n",
    "\n",
    "data_weights_test = np.array([class_weights_test[t] for t in testset.labels])\n",
    "data_weights_test = np.ones_like(testset.labels)\n",
    "\n",
    "second_min_class_count_test =  np.partition(class_counts_test, 1)[1]\n",
    "\n",
    "sampler_test = WeightedRandomSampler(data_weights_test, int(second_min_class_count_test))\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=2, shuffle=False, num_workers=1, sampler=sampler_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    \n",
    "    images, labels = data  \n",
    "    if Flags['useGPU']:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "    if i % 500 == 499:\n",
    "        print('Accuracy of %d batches of test images: %d %%' % (i+1, 100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check per-class performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(4))\n",
    "class_total = list(0. for i in range(4))\n",
    "i = 0\n",
    "for data in testloader:\n",
    "    \n",
    "    images, labels = data\n",
    "    \n",
    "    if Flags['useGPU']:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    for i in range(2):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "    i = i+1\n",
    "    if i > 10000:\n",
    "        break\n",
    "\n",
    "for i in range(4):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_obj = SegmentedImage()\n",
    "\n",
    "img_obj.load_file(data_dir=Dirs['images'], file_name=input_image)\n",
    "img_obj.res['orig'] = img_obj.image_arr[:, :, 1]\n",
    "img_obj.working_arr = img_obj.image_arr[:, :, 1]\n",
    "img_obj.working_arr = imgutil.whiten_image2d(img_obj.working_arr)\n",
    "\n",
    "img_obj.load_mask(mask_dir=Dirs['mask'], fget_mask=get_mask_file, erode=True)\n",
    "img_obj.load_ground_truth(gt_dir=Dirs['truth'], fget_ground_truth=get_ground_truth_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()])\n",
    "dtrain = DriveDatasetFromImageObj(img_obj=img_obj, patch_size=31, transform=transform, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ature_env",
   "language": "python",
   "name": "ature_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
