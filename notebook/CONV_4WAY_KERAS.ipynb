{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook loads and train data from the directories without having them to load on memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('C:\\\\Projects\\\\ature')\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import neuralnet.utils.data_utils as dutils\n",
    "from neuralnet.utils.keras_dataset import KerasPatchesGenerator\n",
    "from commons.IMAGE import Image\n",
    "from PIL import Image as IMG\n",
    "import utils.img_utils as imgutils\n",
    "import neuralnet.utils.keras_vizual_callbacks as kvz\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directories setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define folders. Create if needed.\n",
    "sep = os.sep\n",
    "Dirs = {}\n",
    "Dirs['checkpoint']   = 'assests' +sep+ 'nnet_models'\n",
    "Dirs['data']      = 'data'+sep+'DRIVE'+sep+'training'\n",
    "Dirs['images']    = Dirs['data'] +sep+ 'images'\n",
    "Dirs['mask']      = Dirs['data'] +sep+ 'mask'\n",
    "Dirs['truth']     = Dirs['data'] +sep+ '1st_manual'\n",
    "Dirs['segmented'] = Dirs['data'] +sep+ 'drive_segmented'\n",
    "\n",
    "TestDirs = {}\n",
    "TestDirs['data']      = 'data'+sep+'DRIVE'+sep+'test'\n",
    "TestDirs['images']    = TestDirs['data'] +sep+ 'images1'\n",
    "TestDirs['mask']      = TestDirs['data'] +sep+ 'mask'\n",
    "TestDirs['truth']     = TestDirs['data'] +sep+ '1st_manual'\n",
    "TestDirs['segmented'] = TestDirs['data'] +sep+ 'drive_segmented'\n",
    "\n",
    "ValidationDirs = {}\n",
    "ValidationDirs['data']      = 'data'+sep+'DRIVE'+sep+'test'\n",
    "ValidationDirs['images']    = ValidationDirs['data'] +sep+ 'validation'\n",
    "ValidationDirs['mask']      = ValidationDirs['data'] +sep+ 'mask'\n",
    "ValidationDirs['truth']     = ValidationDirs['data'] +sep+ '1st_manual'\n",
    "ValidationDirs['segmented'] = ValidationDirs['data'] +sep+ 'drive_segmented'\n",
    "\n",
    "for k, folder in Dirs.items():\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "def get_mask_file(file_name): \n",
    "    return file_name.split('_')[0] + '_training_mask.gif'\n",
    "\n",
    "def get_ground_truth_file(file_name): \n",
    "    return file_name.split('_')[0] + '_manual1.gif'\n",
    "\n",
    "def get_segmented_file(file_name):\n",
    "    return file_name + '_SEG.PNG'\n",
    "\n",
    "def get_mask_file_test(file_name): \n",
    "    return file_name.split('_')[0] + '_test_mask.gif'\n",
    "\n",
    "classes = {\n",
    "    'white': 0,\n",
    "    'green': 1,\n",
    "    'black': 2,\n",
    "    'red': 3\n",
    "}\n",
    "batch_size = 120\n",
    "num_classes = len(classes)\n",
    "epochs = 10\n",
    "patch_size = 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 36567 batches found.\n",
      "### 3650 batches found.\n",
      "### 1806 batches found.\n"
     ]
    }
   ],
   "source": [
    "train_generator = KerasPatchesGenerator(Dirs=Dirs, patch_size=patch_size, \n",
    "                                   num_classes=num_classes,\n",
    "                                   fget_mask=get_mask_file, \n",
    "                                   fget_truth=get_ground_truth_file,\n",
    "                                   fget_segmented=get_segmented_file,\n",
    "                                   batch_size=batch_size, transformation=imgutils.whiten_image2d)\n",
    "\n",
    "validation_generator = KerasPatchesGenerator(Dirs=ValidationDirs, patch_size=patch_size, \n",
    "                                   num_classes=num_classes,\n",
    "                                   fget_mask=get_mask_file_test, \n",
    "                                   fget_truth=get_ground_truth_file,\n",
    "                                   fget_segmented=get_segmented_file,\n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "test_generator = KerasPatchesGenerator(Dirs=TestDirs, patch_size=patch_size, \n",
    "                                   num_classes=num_classes,\n",
    "                                   fget_mask=get_mask_file_test, \n",
    "                                   fget_truth=get_ground_truth_file,\n",
    "                                   fget_segmented=get_segmented_file,\n",
    "                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() \n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(patch_size, patch_size, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate Adam optimizer\n",
    "opt = keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using Adam\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=Dirs['checkpoint'] + 'keras_model_checkpoint.hdf5', verbose=1, save_best_only=True)\n",
    "callbacks = [checkpointer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model from directory generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/10\n",
      " 259/5000 [>.............................] - ETA: 23:19 - loss: 6.9470 - acc: 0.3082"
     ]
    }
   ],
   "source": [
    "class_weights = dutils.get_class_weights(np.array(train_generator.IDs)[:,3])\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=5000,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800, verbose=1,\n",
    "        callbacks=callbacks, workers=5,\n",
    "        class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### If we shuffle, we won't be able to generate a segmented image.\n",
    "prediction = model.predict_generator(test_generator, worker=3)\n",
    "pred = np.argmax(prediction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_obj = Image()\n",
    "img_obj.load_file(data_dir=Dirs['images'], file_name='21_training.tif')\n",
    "img_obj.working_arr = img_obj.image_arr[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = np.zeros_like(img_obj.working_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(pred, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, ID in enumerate(test_generator.IDs, 0):\n",
    "    ID, i, j = ID\n",
    "    try:\n",
    "        if pred[ix]==classes['white'] or pred[ix]==classes['red']:\n",
    "            seg[int(i),int(j)] = 255\n",
    "    except:\n",
    "        pass\n",
    "IMG.fromarray(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SANITY CHECK\n",
    "for ID, i, j, y in train_generator.IDs:\n",
    "    if ID==0:\n",
    "        seg[i,j] = 255 if y == 0 or y == 3 else seg[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 8.0, 1: 16.0, 2: 1.0, 3: 31.0}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ature_env",
   "language": "python",
   "name": "ature_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
